{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "This part of the project consists of building an activity recognition system. The activities are classified as low, medium, and high. The data is collected from the participants of the AffecTech project. The participants sit during lectures and meeting, lie down during mindfullness, and stand during presentation.\n",
    "\n",
    "* low: sitting, standing, lie down    \n",
    "* medium: walking   \n",
    "* high: exercising\n",
    "\n",
    "# 2. Data\n",
    "The given data includes Empatica data for each device and information tables. The information tables from the project consists of 4 files:\n",
    "* Mapping from participant number to device numbers\n",
    "* Presentation start and end times excluding Q&A session for each participant in October 7, 2018.\n",
    "* Presentation start and end times including Q&A session for each participant in October 6, 2018.\n",
    "* Start and end times for walking, sitting, exercising, and standing for all participants between September 30, 2018 and October 7, 2018.\n",
    "\n",
    "# 3. Data preprocessing\n",
    "## 3.1. Get accelerometer data from Empatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "os.chdir(os.getcwd())\n",
    "acc_files = glob.glob('ACC.csv' )\n",
    "print(acc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def append_acc_file_to_dataframe(file_name):\n",
    "    file_location = cwd + \"/\" + file_name\n",
    "    with open(file_location, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        start_time = 0\n",
    "        values = []\n",
    "        times = []\n",
    "        prev_time = 0\n",
    "        for i, line in enumerate(reader):\n",
    "            if i is 0:\n",
    "                start_time = float(line[0])\n",
    "                prev_time = start_time\n",
    "            elif i is 1:\n",
    "                frequency_acc = float(line[1])\n",
    "            else:\n",
    "                if start_time + 10 <= prev_time: # Since all sensors start collecting data at the same instant except HR which starts after 10 s\n",
    "                    times.append(prev_time)\n",
    "                    values.append(np.array(line).astype(np.float))\n",
    "                prev_time += 1/frequency_acc\n",
    "    return pd.DataFrame(\n",
    "        {'time': times,\n",
    "         'value_acc': values,\n",
    "         'device': re.findall(\"_(.*?)\\/\", file_name)[0]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "acc_list = []\n",
    "for file in acc_files:\n",
    "    acc_list.append(append_acc_file_to_dataframe(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Convert data from time domain to frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def acc_time_domain_to_frequency_domain(df, frequency):\n",
    "    brand_new_df = pd.DataFrame()\n",
    "    num_rows = df.shape[0]\n",
    "    i = 0\n",
    "    while i < (num_rows - 8 * 60 * frequency):\n",
    "        x = df.iloc[i:(i + (8 * 60 * int(frequency)))]['value_acc'].str[0].astype(float).as_matrix()\n",
    "        y = df.iloc[i:(i + (8 * 60 * int(frequency)))]['value_acc'].str[1].astype(float).as_matrix()\n",
    "        z = df.iloc[i:(i + (8 * 60 * int(frequency)))]['value_acc'].str[2].astype(float).as_matrix()\n",
    "        mean_x = sum(x)/len(x)\n",
    "        mean_y = sum(y)/len(y)\n",
    "        mean_z = sum(z)/len(z)\n",
    "        mag_mean = (mean_x**2 + mean_y**2 + mean_z**2)**(1/2)\n",
    "        std_x = statistics.stdev(x)\n",
    "        std_y = statistics.stdev(y)\n",
    "        std_z = statistics.stdev(z)\n",
    "        mag_std = (std_x**2 + std_y**2 + std_z**2)**(1/2)\n",
    "        mag = [(a**2 + b**2 + c**2)**(1/2) for a,b,c in zip(x, y, z)]\n",
    "        fft_mag = np.fft.fft(mag)\n",
    "        f = np.linspace(0, frequency, len(mag))\n",
    "        df_new = pd.DataFrame(\n",
    "                    {\n",
    "                     'start_time': df['time'][i],\n",
    "                     'end_time': df['time'][i + (8 * 60 * int(frequency)) - 1],\n",
    "                     'mean_x': [mean_x],\n",
    "                     'mean_y': [mean_y],\n",
    "                     'mean_z': [mean_z],\n",
    "                     'mag_mean': [mag_mean],\n",
    "                     'std_x': [std_x],\n",
    "                     'std_y': [std_y],\n",
    "                     'std_z': [std_z],\n",
    "                     'mag_std': [mag_std],\n",
    "                     'mag': [mag],\n",
    "                     'fft': max(fft_mag),\n",
    "                     'device': df['device'][i]\n",
    "                    })\n",
    "        i = i + (8 * 60 * int(frequency))\n",
    "        brand_new_df = pd.concat([brand_new_df, df_new], ignore_index=True)\n",
    "    return brand_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = []\n",
    "for frame in acc_list:\n",
    "    acc_df.append(acc_time_domain_to_frequency_domain(frame, 32))\n",
    "acc_df = pd.concat(acc_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Add label data from information tables\n",
    "activity_labels.csv has the following columns:\n",
    "* **UTC_start:** Start time of the activity\n",
    "* **UTC_end:** End time of the activity\n",
    "* **date:** Date of the activity (month and day)\n",
    "* **label:** Level of the activity (low, medium, or high)\n",
    "* **stress:** Predefined stress level of the activity (btw. 1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(\"activity_labels.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Merge Empatica data and label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df['fft_real'] = acc_df['fft'].real\n",
    "acc_df.drop(['fft'], axis=1, inplace=True)\n",
    "acc_df.drop(['mag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:1534: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "# Merge label data and accelerometer data\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(':memory:')\n",
    "acc_df.to_sql('acc_df', conn, index=False)\n",
    "label_df.to_sql('label_df', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select\n",
    "        acc_df.mag_mean mag_mean,\n",
    "        acc_df.mag_std mag_std,\n",
    "        acc_df.mean_x mean_x,\n",
    "        acc_df.mean_y mean_y,\n",
    "        acc_df.mean_z mean_z,\n",
    "        acc_df.std_x std_x,\n",
    "        acc_df.std_y std_y,\n",
    "        acc_df.std_z std_z,\n",
    "        acc_df.fft_real fft_real,\n",
    "        acc_df.start_time UTC_start,\n",
    "        acc_df.end_time UTC_end,\n",
    "        label_df.label label,\n",
    "        label_df.stress stress\n",
    "    from\n",
    "        label_df\n",
    "    join\n",
    "        acc_df\n",
    "    on\n",
    "        (acc_df.start_time >= label_df.UTC_start) and (label_df.UTC_end >= acc_df.end_time)\n",
    "    '''\n",
    "acc_label_df = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Handling imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with low activity:  1389\n",
      "Number of rows with medium activity:  217\n",
      "Number of rows with high activity:  22\n"
     ]
    }
   ],
   "source": [
    "df_low = acc_label_df[acc_label_df.label==\"low\"]\n",
    "df_medium = acc_label_df[acc_label_df.label==\"medium\"]\n",
    "df_high = acc_label_df[acc_label_df.label==\"high\"]\n",
    "\n",
    "# Number of rows for all labels\n",
    "print(\"Number of rows with low activity: \", df_low.shape[0])\n",
    "print(\"Number of rows with medium activity: \", df_medium.shape[0])\n",
    "print(\"Number of rows with high activity: \", df_high.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Empatica data for low, medium and high activities are imbalanced, it is crucial to balance the classes. The class with least number of instances (high) has 22 instances and the class with most number of instances (low) has 1389 instances. In order to provide the machine learning models with sufficient number of instances, we will upsample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "n_rows = df_low.shape[0]\n",
    "\n",
    "df_high_upsampled = resample(df_high, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=n_rows,\n",
    "                                 random_state=123) # in order to attain reproducible results\n",
    "\n",
    "df_medium_upsampled = resample(df_medium, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=n_rows,\n",
    "                                 random_state=123) # in order to attain reproducible results\n",
    "\n",
    "df_upsampled = pd.concat([df_low, df_high_upsampled, df_medium_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_upsampled[['mag_mean', 'mag_std', 'mean_x', 'mean_y', 'mean_z', 'std_x', 'std_y', 'std_z', 'fft_real']]\n",
    "y = df_upsampled[['label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Logistic Regression\n",
    "### 4.1.1. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mag_mean', 'mag_std', 'mean_y', 'mean_z', 'std_x', 'std_y']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5, multi_class='ovr', class_weight='balanced')\n",
    "sfm = SelectFromModel(clf, threshold=\"0.75*mean\")\n",
    "sfm.fit(X, y)\n",
    "selected_features = np.array(list(X.columns))\n",
    "result = selected_features[sfm.get_support()]\n",
    "result.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to **SelectFromModel**, mag_std, mean_y, mean_z, std_x, and std_y are selected as features for logistic regression classifier\n",
    "### 4.1.2. Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8069544364508393"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lr = df_upsampled[['mag_mean', 'mag_std', 'mean_y', 'mean_z', 'std_x', 'std_y']]\n",
    "y_lr = df_upsampled[['label']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lr, y_lr, test_size=0.2)\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5, multi_class='ovr', class_weight='balanced').fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Naive Bayes\n",
    "### 4.2.1. Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8141486810551559"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_nb = df_upsampled[['mag_mean', 'mag_std', 'mean_x', 'mean_y', 'mean_z', 'std_x', 'std_y', 'std_z', 'fft_real']]\n",
    "y_nb = df_upsampled[['label']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nb, y_nb, test_size=0.2)\n",
    "\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb.predict(X_test)\n",
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Decision Tree\n",
    "### 4.3.1. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mag_std', 'mean_z', 'fft_real']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "sfm = SelectFromModel(clf, threshold=\"0.75*mean\")\n",
    "sfm.fit(X, y)\n",
    "selected_features = np.array(list(X.columns))\n",
    "result = selected_features[sfm.get_support()]\n",
    "result.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to **SelectFromModel**, mag_std and mean_z are selected as features for Decision Tree classifier.\n",
    "### 4.3.2. Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9617224880382775"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dt = df_upsampled[['mag_std', 'mean_z','fft_real']]\n",
    "y_dt = df_upsampled[['label']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dt, y_dt, test_size=0.05)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808612440191388"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dt = df_upsampled[['mag_std', 'mean_x', 'mean_y', 'mean_z', 'std_x', 'std_y', 'std_z', 'fft_real']]\n",
    "y_dt = df_upsampled[['label']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dt, y_dt, test_size=0.05)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Multi-layer Perceptron\n",
    "### 4.4.1. Model Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31100478468899523"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_mlp = df_upsampled[['mag_mean', 'mag_std', 'mean_x', 'mean_y', 'mean_z', 'std_x', 'std_y', 'std_z', 'fft_real']]\n",
    "y_mlp = df_upsampled[['label']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mlp, y_mlp, test_size=0.05)\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion\n",
    "\n",
    "Highest score is 0.98 and is attained by decision tree. We can use this classifier during stress detection in order to see whether stress indicating signals are caused by high activity or stressful conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dt = df_upsampled[['mag_mean', 'mag_std', 'mean_x', 'mean_y', 'mean_z', 'std_x', 'std_y', 'std_z', 'fft_real']]\n",
    "y_dt = df_upsampled[['label']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dt, y_dt, test_size=0.05)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "result = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled['predicted_y'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled.to_csv(\"detected_activity.csv\", sep='\\t', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
